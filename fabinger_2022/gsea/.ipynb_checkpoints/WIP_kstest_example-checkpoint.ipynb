{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edfa6059",
   "metadata": {},
   "source": [
    "<h6>KS Test</h6>\n",
    "Given n samples, order them the empirical CDF is \n",
    "$$\n",
    "E_N = \\frac{n(i)}{N}\n",
    "$$\n",
    "where n(i) is the number less than $Y_i$ and $Y_i$ are ordered from smallest to largest.\n",
    "#https://www.itl.nist.gov/div898/handbook/eda/section3/eda35g.htm\n",
    "\n",
    "<p>The CDF is a continuously increasing function in the graph above for 100 ordered random numbers\n",
    "There are several assumptions with the KS tests\n",
    "<li>1)only for continuous distributions</li>\n",
    "<li>2)more sensitive near center than at tails</li>\n",
    "<li>3)most serious limitation is distribution must be fully specified. \n",
    "That is, if location, scale, and shape parameters are estimated from the data, \n",
    "the critical region of the K-S test is no longer valid. \n",
    "It typically must be determined by simulation.</li>\n",
    "</p>\n",
    "<p>Several goodness-of-fit tests, such as the Anderson-Darling test and the Cramer Von-Mises test, \n",
    "are refinements of the K-S test. As these refined tests are generally considered \n",
    "to be more powerful than the original K-S test, \n",
    "many analysts prefer them. Also, the advantage for the K-S test of \n",
    "having the critical values be indpendendent of the underlying distribution \n",
    "is not as much of an advantage as first appears. \n",
    "This is due to limitation 3 above (i.e., the distribution parameters are \n",
    "typically not known and have to be estimated from the data). \n",
    "So in practice, the critical values for the K-S test have to be \n",
    "determined by simulation just as for the Anderson-Darling and Cramer Von-Mises (and related) tests.\n",
    "\n",
    "Note that although the K-S test is typically developed in the context of continuous distributions for \n",
    "uncensored and ungrouped data, the test has in fact been extended to discrete distributions and to \n",
    "censored and grouped data. \n",
    "We do not discuss those cases here.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca01772a",
   "metadata": {},
   "source": [
    "#https://online.stat.psu.edu/stat415/book/export/html/838\n",
    "<h6>KS test</h6>\n",
    "<p>The KS Test is a hypothesis test which tests if a hypothesis emprical cumulative distribution function $F_h$ for an ordered set of can be defined below as  $F_h$ by diving the probabity into equal probabiities for each \n",
    "ordered value. This is an example of generating a test statistic by rearranging our data into an ordered set. \n",
    "Given an observed sample from a Random Variable $X$, $x_1,x_2,...x_n$ then the empirical distribution function $F_h$ is equal to the number of $x_n$ which is less or equal to a given value x. This value \"x\" is not a single value but a set of ordered values $y_1, y_2, ... y_n$ where $y_1<y_2, ...$. $F_h$ is defined as \n",
    " $$\n",
    " F_h = \\left\\{\n",
    "     \\begin{array}{11}\n",
    "     0\\ for\\ x<y_1\\\\\n",
    "     \\frac{k}{n}\\ for\\ y_k<=x<y_{k+1}\\ k=1,2,...(n-1)\\\\\n",
    "     1\\ for\\ x>=y_n\n",
    "     \\end{array}   \n",
    "    \\right.\n",
    " $$\n",
    "     If 2 observations are equal $F_n$ changes by $1$ and if observations are not equal then $F_n$ changes by $2$.Looks reversed and wrong? \n",
    "</p>\n",
    "<P>The ordering allows us to compare to a CDF and plot on a graph to compate the EDF vs a CDF. This allows us to\n",
    "     do hypothesis testing between an EDF and CDF. q) we can order from highest to lowest to give a 1 sided statistic\n",
    "     can we order by peak, then distribute the next 2 highest values on either side to create a 2 tailed statistic? Proof?</P>\n",
    "     \n",
    "<p>why is there no such thing as an empirical PDF? only an empirical CDF? We have to use the ordered statistic for CDF. \n",
    "     Whereas a RV coin/die can have a CDF and PDF. Test with simulation.empirical CDF to bernoulli RV and multinomial RV CDF</p>  \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2462ec",
   "metadata": {},
   "source": [
    "<h6>Example find Empirical CDF</h6>\n",
    "<p>A random sample of n=8 people swim x number of times per week. 8 people swam per week: {0 1 2 2 4 6 6 7}. k=8. Calculate the empirical distribution function $F_h$ The first\n",
    "    step is to order the $y_n observations$. The smallest value is 0 which is $y_1$, $F_h = 0\\ for\\ x<0$. Iterate through k for unique ordered $y_n$,k=1; $1<=x<2$ $F_h = \\frac{1}{8}$,k=2; $2<=x<4$ $F_h = \\frac{2}{8}+$, k=3;$4<x<5$ $F_h = \\frac{1}{8}$  </p>\n",
    "    <p>A more clear derivation is to look at each interval and count the number of observagions less than k.\n",
    "    $x<0$, \n",
    "    <br/>\n",
    "    $0<=x<1$, fraction less than 1=1/8\n",
    "    <br/>\n",
    "    $1<=x<2$,fraction less than 2: 2/8\n",
    "    <br/>\n",
    "    $2<=x<4$,fraction less than 4: 4/8\n",
    "    <br/>\n",
    "    $4<=x<6$, fraction less than 6: 5/8\n",
    "    <br/>\n",
    "    $6<=x<7$, fraction less than 7: 7/8\n",
    "    <br/>\n",
    "    $7<=x$, equal to 1. \n",
    "    <br/>\n",
    "    </p>\n",
    "    <p>An easy mistake is to treat the inequality as intervals and include all the observations less than the current value. We\n",
    "    are cmputing a CDF not PDF</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ba5045",
   "metadata": {},
   "source": [
    "<h6>KS test statistic</h6>\n",
    "<p>\n",
    "$D_n = sup_x|F_h(x)-F_0(x)|$ where the supremum is the absolute max of the difference between the hypothesis function\n",
    "and empirical distribution function. $D_n$ is the upper bound of the difference between the 2 distribution. Is this the sum of \n",
    "all the differences vs. one absolute difference? Seems odd if 1 observation can be a valid hypothesis. What if it is an outlier? \n",
    "</p>\n",
    "<p>How to prove $F_h$ with probability 1 and uniformly in x, to the theoretical distribution function $F(x)$? Need to clear up\n",
    "definitions, This is to the hypothesis distribution or to any distribution? </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07503364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.random._generator.Generator'>\n",
      "[-15.   -11.25  -7.5   -3.75   0.     3.75   7.5   11.25  15.  ]\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "print(type(rng))\n",
    "x = np.linspace(-15, 15, 9)\n",
    "stats.kstest(x,cdf='norm')\n",
    "#KstestResult(statistic=0.4443560271592436, pvalue=0.03885014008678811)\n",
    "#this is or isnt normal data? \n",
    "print(x)\n",
    "#this uses a MC simulation for the norm to calculate the test statistic\n",
    "#https://towardsdatascience.com/how-to-compare-two-distributions-in-practice-8c676904a285\n",
    "    \n",
    "#use a montecarlo simulation\n",
    "\n",
    "#when do you need to test for uniform pvalue. Cant just say 5% p value. What is a dynamic null hypothesis. \n",
    "#when data is nonstationary, eg weekly batch updates. \n",
    "#https://towardsdatascience.com/how-to-test-your-hypothesis-using-p-value-uniformity-test-e3a43fc9d1b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af457f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "If this is true? \n",
    "https://stats.stackexchange.com/questions/208517/kolmogorov-smirnov-test-vs-t-test\n",
    "\n",
    "\n",
    "the t-test uses mean. if the variances are different then the t-test doesnt pick that up but kstest does? \n",
    "need example\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/how-to-compare-two-distributions-in-practice-8c676904a285\n",
    "https://cran.r-project.org/web/packages/dgof/dgof.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50d8808",
   "metadata": {},
   "source": [
    "<h6>Binomial RV</h6>\n",
    "A binomial Random variable has 4 assumpptions:\n",
    "<li>1) N is fixed, the number of observations</li>\n",
    "<li>2) each observation is independent. Each coin flip is independent</li>\n",
    "<li>3) each observation has to take 1 out of 2 outcomes, H or T</li>\n",
    "<li>4) the probablity P of success is same for each outcome. We encode the H/T into number of successes and number of failuers\n",
    "with 1-num_sucess=num_failures</li>\n",
    "\n",
    "\n",
    "The PMF of a binomial RV is: \n",
    "$$\n",
    "f(n,k,p) = P(X=x) =  \\binom{n}{k}p^{k}(1-p)^{n-k}\n",
    "$$\n",
    "the CDF or the integral of the PDF is: \n",
    "$$\n",
    "CDF(n,k,p) = P(X<k) = \\sum_i^{floor(k)}\\binom{n}{i}p^i(1-p)^{n-i}\n",
    "$$\n",
    "Another form of the CDF:\n",
    "$$\n",
    "CDF(n,k,p)=P(X<k) = I_{1-p}(n-k,k+1)=(n-k)\\binom{n}{k}\\int_0^{1-p}t^{n-k-1}(1-t)^k dt\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91698b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<scipy.stats._distn_infrastructure.rv_frozen object at 0x1253232b0>\n",
      "50068 49932\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "n, p = 5, 0.4\n",
    "\n",
    "from scipy.stats import bernoulli\n",
    "p=0.5\n",
    "rv=bernoulli(p)\n",
    "print(rv)\n",
    "r = bernoulli.rvs(p, size=10)\n",
    "num_0 = [x for x in r if x==0]\n",
    "num_1 = [x for x in r if x==1]\n",
    "\n",
    "print(len(num_0),len(num_1))\n",
    "\n",
    "r = bernoulli.rvs(p, size=20)\n",
    "num_0 = [x for x in r if x==0]\n",
    "num_1 = [x for x in r if x==1]\n",
    "\n",
    "print(len(num_0),len(num_1))\n",
    "r = bernoulli.rvs(p, size=100)\n",
    "num_0 = [x for x in r if x==0]\n",
    "num_1 = [x for x in r if x==1]\n",
    "\n",
    "print(len(num_0),len(num_1))\n",
    "\n",
    "#hypothesis test are each of those from p=0.5? \n",
    "#H0: the BRV is a fair coin\n",
    "#HA: \n",
    "\n",
    "#different \n",
    "\n",
    "\n",
    "#statistical power test? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4defdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "source: https://www.youtube.com/watch?v=Mq4j_bQvFYY\n",
    "$$\n",
    "prior \\sim Beta(\\alpha, \\beta)\n",
    "$$\n",
    "\n",
    "$$\n",
    "posterior \\sim Beta(\\alpha+\\sum_1^{n}x_i, \\beta+n - \\sum_1^{n}x_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "mean=\\frac{\\alpha}{\\alpha+\\beta}\n",
    "$$\n",
    "\n",
    "$$\n",
    "var = \\frac{\\alpha \\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}\n",
    "$$\n",
    "\n",
    "<p>I cant get the wiki to match with this</p>\n",
    "$$\n",
    "P(p \\le p_0) = \\int_{0}^{p_0}\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}p^{\\alpha-1}(1-p)^{\\beta-1}=R\\ function\\ pbeta()\n",
    "$$\n",
    "Z is interested in proportion of new mothers who enroll. Z believes 10% of new mothers enroll. \n",
    "$$\n",
    "H_0:p \\le 1 \\\\\n",
    "H_A: p \\gt 1\n",
    "$$\n",
    "Use prior Beta(1,1) which is uniform distribution which means P(H0)=.1 and P(HA)=0.9 which biases towards HA. \n",
    "This is counterintuitive. What we really expect for a uniform distribution is P(H0)=P(HA)=50%=.5. Both equally likely\n",
    "is a mental model of no bias or no information about a prior. Trial and Error gives Beta(2,16) for P(H0)=0.5. Is  there a better\n",
    "way to do this? Yes but not in video. Z takes a sample and gets 26/232 enrolled. \n",
    "$$\n",
    "P(p|D)\\sim Beta(\\alpha+\\sum_1^{n}x_i, \\beta+n - \\sum_1^{n}x_i)=Beta(28,222) \\\\\n",
    "P(p\\le 0.1 | D) = .2847 \\n P(p \\gt 0.1 | D) = .7153\n",
    "$$\n",
    "This is MAP technique where we take Maximum of posterior probability. Simple but not always best estimator. \n",
    "HA more likely than H0. \n",
    "He presents 2 priors, a 10% and 50%. \n",
    "\n",
    "<h6>Setting parameters 3 ways</h6>\n",
    "<li>1) Uniform</li>\n",
    "<li>1) Success/Faiulres</li>\n",
    "<li>1) method of moments</li>\n",
    "<p>E wants to know proportion of museum goers who will pay to be become members. Assumes uniform prior for \n",
    "all visitors Beta(1,1) and then surveys to find 32/52 would become members. </p>\n",
    "\n",
    "$$\n",
    "P(p|D)\\sim Beta(\\alpha+\\sum_1^{n}x_i, \\beta+n - \\sum_1^{n}x_i)=Beta(33,21) \\\\\n",
    "qbeta()=(.4789,.7354)\n",
    "$$\n",
    "\n",
    "\n",
    "#bayes factors is topic for same type problem not covered yet. \n",
    "#is BF comparable to ANOVA? Maybe. Bayes factor is a ratio of prior to posterior result is fractional value similar to pvalue\n",
    "#effect sizes and bayes factors\n",
    "#vs. effect sizes and power in frequentist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b6d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('cosmic')",
   "language": "python",
   "name": "python397jvsc74a57bd053d4678d88891fb05e04416eb1a742497c0b0baabdd52f6ad28cb1ed11944cce"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
